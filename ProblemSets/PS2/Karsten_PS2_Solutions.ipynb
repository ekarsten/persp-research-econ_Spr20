{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eric Karsten PSET  Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Parallel computing versus serial computing a bootstrapped cross validation \n",
    "For this exercise, you will use the same Auto.csv file. This dataset includes 397 observations on miles per gallon (mpg), number of cylinders (cylinders), engine displacement (displacement), horsepower (horsepower), vehicle weight (weight), acceleration (acceleration), vehicle year (year), vehicle origin (origin), and vehicle name (name). We will study the factors that make miles per gallon high or low. Create a binary variable mpg high that equals 1 if mpg\\_high $\\geq$ median(mpg\\_high) and equals 0 if mpg\\_high $<$ median(mpg\\_high). Create two indicator variables for vehicle origin 1 (orgn1) and vehicle origin 2 (orgn2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cars = pd.read_csv('data/Auto.csv')\n",
    "\n",
    "# Small cleaning step\n",
    "cars = cars[cars[\"horsepower\"] != \"?\"]\n",
    "cars[\"horsepower\"] = cars[\"horsepower\"].astype(float)\n",
    "\n",
    "# Data Preparation\n",
    "y = pd.DataFrame((cars.mpg <= np.median(cars.mpg)).astype(int))\n",
    "X = cars[[\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"year\"]]\n",
    "X.loc[:,\"orgn1\"] = (cars.origin == 1).astype(int)\n",
    "X.loc[:,\"orgn2\"] = (cars.origin == 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Serial Logit\n",
    "Using serial computation, perform an estimation of the logistic model on 100 bootstrapped training sets (with replacement) on random draws of training sets of 65% of the data. Use sklearn.linear model.LogisticRegression() function and make sure that the n jobs option is set to None or 1. This will guarantee that it runs in serial. Compute the error rate for each of the 100 test sets. Calculate the average error rate. Make sure to set the seed on each of the 100 random draws so that these draws can be replicated in part (b). What is your error rate? How long did this computation take?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The serial computation took  9.08  seconds.\n",
      "The mean error from serial computation was  0.07992156862745096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from time import process_time \n",
    "\n",
    "index = np.array(X.index)\n",
    "\n",
    "\n",
    "def logit_error(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    train_index = np.random.choice(index, size=round(len(index) * .65), replace=True)\n",
    "    test_index = np.setdiff1d(index, train_index)\n",
    "\n",
    "    X_train = np.array(X.loc[train_index, :])\n",
    "    X_test = np.array(X.loc[train_index, :])\n",
    "    y_train = np.array(y.loc[train_index, :]).flatten()\n",
    "    y_test = np.array(y.loc[train_index, :]).flatten()\n",
    "\n",
    "    mod = LogisticRegression(solver='lbfgs', max_iter=10000, n_jobs=None)\n",
    "    fit_mod = mod.fit(X_train, y_train)\n",
    "    y_test_predict = fit_mod.predict(X_test)\n",
    "\n",
    "    error_rate = np.mean(y_test != y_test_predict)\n",
    "    return error_rate\n",
    "\n",
    "\n",
    "time_start = process_time()\n",
    "\n",
    "serial_errors = []\n",
    "for i in range(0,100):\n",
    "    serial_errors.append(logit_error(i))\n",
    "\n",
    "time_elapsed = (process_time() - time_start)\n",
    "\n",
    "\n",
    "\n",
    "print(\"The serial computation took \", round(time_elapsed, 2), \" seconds.\")\n",
    "print(\"The mean error from serial computation was \", np.mean(serial_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Parallel Logit\n",
    "Now write a function that takes as arguments the bootstrap number (1 through 100 or 0 through 99), random seed, and the data, and estimates the logistic model on 65% of the data and calculates an error rate on the remaining 35%. Use Dask to parallelize these bootstraps. What is your error rate from this parallelized list of error rates? It should be the same\n",
    "as part (a). How long did this computation take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parallel computation took  0.59  seconds.\n",
      "The mean error from parallel computation was  0.07992156862745096\n"
     ]
    }
   ],
   "source": [
    "from dask import compute, delayed\n",
    "import dask.multiprocessing\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "time_start = process_time()\n",
    "\n",
    "parallel_errors = []\n",
    "for i in range(0,100):\n",
    "    parallel_errors.append(delayed(logit_error)(i))\n",
    "\n",
    "results_par = compute(*parallel_errors, scheduler=dask.multiprocessing.get, num_workers=num_cores)\n",
    "    \n",
    "time_elapsed = (process_time() - time_start)\n",
    "\n",
    "print(\"The parallel computation took \", round(time_elapsed, 2), \" seconds.\")\n",
    "print(\"The mean error from parallel computation was \", np.mean(results_par))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
